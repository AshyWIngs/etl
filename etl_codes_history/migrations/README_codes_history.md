# Codes History — полностью автоматическая дедупликация по (c, t, opd)

## Что сделано
- Вся логика уникальности сосредоточена в ClickHouse:
  - `stg.daily_codes_history_all` — сырец.
  - `stg.daily_codes_history` — финал, уникальность строго по `(c, t, opd)`.
  - `stg.mv_daily_codes_history_dedup` — MATERIALIZED VIEW, который:
    1) Внутри одного батча объединяет дубли по `(c, t, opd)` (GROUP BY).
    2) Не вставляет ключи, которые уже есть в финале (LEFT JOIN ... WHERE f.c IS NULL).

## Как использовать в ETL
**Просто вставляйте** данные в `stg.daily_codes_history_all` теми колонками, что в DDL.
Никаких дополнительных шагов по чистке дублей не нужно — MV сделает всё сам.

### Почему этого достаточно
- Повторы в одном батче: схлопываются `GROUP BY` в MV.
- Повторы из-за повторного запуска окна: ключ уже будет в финале — MV их отсечёт.

## Поля и типы
- Ключ: `(c String, t Int32, opd DateTime64(3, 'UTC'))`.
- `ch Array(String) DEFAULT [] CODEC(ZSTD(6))` — детские коды, как вы и просили.
- Все DateTime храним в оригинале (миллисекунды поддержаны). Смещение делается только при чтении из источника.

## Бэктилл/ручная дозагрузка (опционально)
Если нужно переиграть окно вручную, используйте `02_upsert_window.sql` — он делает
идемпотентную вставку без удаления, с той же логикой дедупликации.

## Проверки
`03_checks.sql` — быстрые проверки дублей и сверки объёмов между сырцом и финалом.

## Что мы **не** используем
- Никаких `cityHash64`, `id`, `q`, `etl_job`, `load_id` и т.д.
- Минимум системных полей: только `ingested_at` в финале (для аудита).
- В сырце поле `ts` опционально — если не присылаете, оно просто NULL.

## Порядок развёртывания
1. Выполнить `01_clickhouse_ddl.sql` на всех репликах.
2. Запустить ваш ETL — он будет писать в `stg.daily_codes_history_all`.
3. Проверить качество `03_checks.sql` (по окну, если нужно).

Готово: процесс полностью автоматический, ручной чистки дублей не требуется.